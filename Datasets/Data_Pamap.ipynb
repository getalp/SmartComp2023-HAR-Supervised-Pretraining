{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import requests \n",
    "import urllib.request\n",
    "import zipfile\n",
    "from scipy import stats\n",
    "import scipy.signal\n",
    "import tensorflow as tf\n",
    "import hickle as hkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a680c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd53eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "            \n",
    "def create_segments_and_labels_PAMAP(df, time_steps, step, label_name = \"LabelsEncoded\", n_features= 6):\n",
    "    \n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        acc_x = df['acc_x'].values[i: i + time_steps]\n",
    "        acc_y = df['acc_y'].values[i: i + time_steps]\n",
    "        acc_z = df['acc_z'].values[i: i + time_steps]\n",
    "\n",
    "        gyro_x = df['gyro_x'].values[i: i + time_steps]\n",
    "        gyro_y = df['gyro_y'].values[i: i + time_steps]\n",
    "        gyro_z = df['gyro_z'].values[i: i + time_steps]\n",
    "\n",
    "    \n",
    "\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        reshaped = np.dstack([acc_x,acc_y,acc_z,gyro_x,gyro_y,gyro_z]).reshape(time_steps, n_features)\n",
    "        segments.append(reshaped)\n",
    "        labels.append(label)\n",
    "    \n",
    "    \n",
    "    return np.asarray(segments), np.asarray(labels)\n",
    "\n",
    "def standardize_data(deviceData):\n",
    "\n",
    "    deviceDataAcc = deviceData[:,:,:3].astype(np.float32)\n",
    "    deviceDataGyro = deviceData[:,:,3:].astype(np.float32)\n",
    "    accMean =  np.mean(deviceDataAcc)\n",
    "    accStd =  np.std(deviceDataAcc)\n",
    "    gyroMean =  np.mean(deviceDataGyro)\n",
    "    gyroStd =  np.std(deviceDataGyro)\n",
    "    deviceDataAcc = (deviceDataAcc - accMean)/accStd\n",
    "    deviceDataGyro = (deviceDataGyro - gyroMean)/gyroStd\n",
    "    deviceData = np.dstack((deviceDataAcc,deviceDataGyro))\n",
    "    \n",
    "    return deviceData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "list_of_files = ['PAMAP2_Dataset/Protocol/subject101.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject102.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject103.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject104.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject105.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject106.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject107.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject108.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject109.dat' ]\n",
    "\n",
    "subjectID = [1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "activityIDdict = {0: 'transient',\n",
    "              1: 'lying',\n",
    "              2: 'sitting',\n",
    "              3: 'standing',\n",
    "              4: 'walking',\n",
    "              5: 'running',\n",
    "              6: 'cycling',\n",
    "              7: 'Nordic_walking',\n",
    "              9: 'watching_TV',\n",
    "              10: 'computer_work',\n",
    "              11: 'car driving',\n",
    "              12: 'ascending_stairs',\n",
    "              13: 'descending_stairs',\n",
    "              16: 'vacuum_cleaning',\n",
    "              17: 'ironing',\n",
    "              18: 'folding_laundry',\n",
    "              19: 'house_cleaning',\n",
    "              20: 'playing_soccer',\n",
    "              24: 'rope_jumping' \n",
    "    }\n",
    "colNames = [\"timestamp\", \"activityID\",\"heartrate\"]\n",
    "colNames_reduced = [\"timestamp\", \"activityID\"]\n",
    "\n",
    "IMUhand = ['handTemperature', \n",
    "           'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n",
    "           'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n",
    "           'handGyro1', 'handGyro2', 'handGyro3', \n",
    "           'handMagne1', 'handMagne2', 'handMagne3',\n",
    "           'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n",
    "\n",
    "IMUchest = ['chestTemperature', \n",
    "           'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n",
    "           'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n",
    "           'chestGyro1', 'chestGyro2', 'chestGyro3', \n",
    "           'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
    "           'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n",
    "\n",
    "IMUankle = ['ankleTemperature', \n",
    "           'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n",
    "           'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n",
    "           'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n",
    "           'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
    "           'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n",
    "\n",
    "\n",
    "only_pocket_setup = ['ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3',  \n",
    "                     'ankleGyro1', 'ankleGyro2', 'ankleGyro3']\n",
    "\n",
    "columns = colNames + IMUhand + IMUchest + IMUankle  #all columns in one list\n",
    "\n",
    "columns_reduced = colNames_reduced + only_pocket_setup\n",
    "\n",
    "len(columns)\n",
    "#len(columns_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = [\"pamap2+physical+activity+monitoring\"]\n",
    "links = [\"https://archive.ics.uci.edu/static/public/231/pamap2+physical+activity+monitoring.zip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70601e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('dataset/download',exist_ok=True)\n",
    "os.makedirs('dataset/extracted',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fileName)):\n",
    "    data_directory = os.path.abspath(\"dataset/download/\"+str(fileName[i])+\".zip\")\n",
    "    if not os.path.exists(data_directory):\n",
    "        print(\"downloading \"+str(fileName[i]))            \n",
    "        download_url(links[i],data_directory)\n",
    "        print(\"download done\")\n",
    "        data_directory2 =  os.path.abspath(\"dataset/extracted/\"+str(fileName[i])+\".zip\")\n",
    "        print(\"extracting data...\")\n",
    "        with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.abspath(\"dataset/extracted/\"))\n",
    "        print(\"data extracted\")\n",
    "    else:\n",
    "        print(str(fileName[i]) + \" already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"dataset/extracted/PAMAP2_Dataset\"):\n",
    "    print(\"extracting sub-zip...\")\n",
    "    with zipfile.ZipFile(\"dataset/extracted/PAMAP2_Dataset.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.abspath(\"dataset/extracted/\"))\n",
    "    print(\"data extracted\")\n",
    "else:\n",
    "    print(\"sub-zip already extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87416d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCollection = pd.DataFrame()\n",
    "main_dir = \"dataset/extracted/\"\n",
    "for file in list_of_files:\n",
    "    procData = pd.read_table(main_dir + file, header=None, sep='\\s+')\n",
    "    procData.columns = columns\n",
    "    #procData.columns = columns_reduced\n",
    "    procData['subject_id'] = int(file[-5])\n",
    "    dataCollection = dataCollection.append(procData, ignore_index=True)\n",
    "dataCollection.reset_index(drop=True, inplace=True)\n",
    "dataCollection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a19593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaning(dataCollection):\n",
    "        # removal of orientation columns as they are not needed\n",
    "        dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) #removal of any row of activity 0 as it is transient activity which it is not used\n",
    "        #dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerse') #removal of non numeric data in cells\n",
    "        dataCollection = dataCollection.interpolate() #removal of any remaining NaN value cells by constructing new data points in known set of data points\n",
    "        \n",
    "        return dataCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bffb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol = dataCleaning(dataCollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol.reset_index(drop = True, inplace = True)\n",
    "dataCol.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9569b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    dataCol[\"heartrate\"].iloc[i]=100\n",
    "dataCol.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3037ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol['activityID'].value_counts().plot(kind = \"bar\",figsize = (12,6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol.rename(columns = {\n",
    "                     'ankleAcc16_1':'acc_x',\n",
    "                     'ankleAcc16_2':'acc_y',\n",
    "                     'ankleAcc16_3':'acc_z',\n",
    "    \n",
    "                     'ankleGyro1':'gyro_x',\n",
    "                     'ankleGyro2':'gyro_y',\n",
    "                     'ankleGyro3':'gyro_z',\n",
    "                    \n",
    "                     'activityID':'LabelsEncoded'\n",
    "                    }, inplace = True)\n",
    "dataCol['activityString'] = dataCol['LabelsEncoded'].map(activityIDdict)\n",
    "unique_user_ids = dataCol['subject_id'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_labels = []\n",
    "for user_id in unique_user_ids[:8]:\n",
    "    #print(user_id)\n",
    "    selected_data = dataCol.loc[dataCol['subject_id'] == user_id]\n",
    "    x, y = create_segments_and_labels_PAMAP(selected_data, 256, 128)\n",
    "    \n",
    "    x = scipy.signal.decimate(x, q = 2, n=None, ftype='iir', axis=1, zero_phase=True)\n",
    "    #x_aligned = standardize_data(x)\n",
    "    print(x.shape)\n",
    "    mapping = [-1,6,3,4,5,2,7,8,-1,-1,-1,-1,1,0,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,9]\n",
    "    y_aligned =  np.hstack(mapping[labelIndex] for labelIndex in y)\n",
    "    y_oneHot_aligned = tf.one_hot(y_aligned,10)    \n",
    "    all_data.append(x)\n",
    "    all_labels.append(y_oneHot_aligned)\n",
    "    \n",
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = np.asarray(all_labels)\n",
    "all_data = np.asarray(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectIndex = []\n",
    "for data in all_data:\n",
    "    subjectIndex.append(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5dd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = np.vstack((all_data))\n",
    "standardizedData = standardize_data(allData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectData = []\n",
    "startIndex = 0\n",
    "endIndex = 0\n",
    "for index in subjectIndex:\n",
    "    endIndex += index\n",
    "    subjectData.append(standardizedData[startIndex:endIndex])\n",
    "    startIndex = endIndex\n",
    "subjectData = np.asarray(subjectData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa470e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'PAMAP'\n",
    "os.makedirs('datasetClientsUnion/'+dataName, exist_ok=True)\n",
    "hkl.dump(subjectData,'datasetClientsUnion/'+dataName+ '/clientsData.hkl' )\n",
    "hkl.dump(all_labels,'datasetClientsUnion/'+dataName+ '/clientsLabel.hkl' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
