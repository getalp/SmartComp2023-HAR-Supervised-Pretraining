{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "import requests \n",
    "np.random.seed(0)\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for loading and downloading the dataset\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = np.dstack(loaded)\n",
    "\treturn loaded\n",
    " \n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset(group, prefix='',position=''):\n",
    "\tfilepath = prefix + '/' + group + '/' + position\n",
    "\tfilenames = list()\n",
    "\t# body acceleration\n",
    "\tfilenames += ['Acc_x.txt', 'Acc_y.txt', 'Acc_z.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['Gyr_x.txt', 'Gyr_y.txt', 'Gyr_z.txt']\n",
    "\t# load input data\n",
    "\tx = np.asarray(load_group(filenames, filepath))\n",
    "\t# load class output\n",
    "\ty =  processLabel(load_file(filepath+'/Label.txt'))\n",
    "\treturn x, y\n",
    "\n",
    "# download function for datasets\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = [\"Activity recognition exp\"]\n",
    "links = [\"http://archive.ics.uci.edu/ml/machine-learning-databases/00344/Activity%20recognition%20exp.zip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzipping dataset/download\n",
    "os.makedirs('dataset/download',exist_ok=True)\n",
    "os.makedirs('dataset/extracted',exist_ok=True)\n",
    "\n",
    "for i in range(len(fileName)):\n",
    "    data_directory = os.path.abspath(\"dataset/download/\"+str(fileName[i])+\".zip\")\n",
    "    if not os.path.exists(data_directory):\n",
    "        print(\"downloading \"+str(fileName[i]))            \n",
    "        download_url(links[i],data_directory)\n",
    "        print(\"download done\")\n",
    "        print(\"extracting data...\")\n",
    "        with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.abspath(\"dataset/extracted/\"))\n",
    "        print(\"data extracted\")\n",
    "    else:\n",
    "        print(str(fileName[i]) + \" already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRanges(nums):\n",
    "    nums = sorted(set(nums))\n",
    "    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]\n",
    "    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n",
    "    return list(zip(edges, edges))\n",
    "\n",
    "def unionRange(a):\n",
    "    b = []\n",
    "    for begin,end in sorted(a):\n",
    "        if b and b[-1][1] >= begin - 1:\n",
    "            b[-1][1] = max(b[-1][1], end + 1)\n",
    "        else:\n",
    "            b.append([begin, end + 1])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLabel(labels):\n",
    "    uniqueCount = np.unique(labels,return_counts=True)\n",
    "    if(len(uniqueCount[0]) > 1):\n",
    "        return uniqueCount[0][np.argmax(uniqueCount[1])]\n",
    "    else:\n",
    "        return uniqueCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downSampleLowPass(motionData,factor):\n",
    "    accX = signal.decimate(motionData[:,:,0],factor)\n",
    "    accY = signal.decimate(motionData[:,:,1],factor)\n",
    "    accZ = signal.decimate(motionData[:,:,2],factor)\n",
    "    gyroX = signal.decimate(motionData[:,:,3],factor)\n",
    "    gyroY = signal.decimate(motionData[:,:,4],factor)\n",
    "    gyroZ = signal.decimate(motionData[:,:,5],factor)\n",
    "    return np.dstack((accX,accY,accZ,gyroX,gyroY,gyroZ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentData(accData,time_step,step):\n",
    "#     print(accData.shape)\n",
    "    step = int(step)\n",
    "    segmentAccData = []\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "#         dataSlice = accData[i:i+time_step,:]\n",
    "#         dataSlice = np.delete(dataSlice,sliceIndex,  0)\n",
    "#         segmentAccData.append(dataSlice)\n",
    "#         segmentAccData.append(signal.decimate(accData[i:i+time_step,:],2))\n",
    "        segmentAccData.append(accData[i:i+time_step,:])\n",
    "\n",
    "\n",
    "    return np.asarray(segmentAccData)\n",
    "def segmentLabel(accData,time_step,step):\n",
    "#     print(accData.shape)\n",
    "    segmentAccData = list()\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "        segmentAccData.append(processLabel(accData[i:i+time_step]))\n",
    "    return np.asarray(segmentAccData)\n",
    "\n",
    "\n",
    "def formatData(data,dim):\n",
    "    remainders = data.shape[0]%dim\n",
    "    max_index = data.shape[0] - remainders\n",
    "    data = data[:max_index,:]\n",
    "    new = np.reshape(data, (-1, 128,3))\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, treshHoldSplit,stepsize=1):\n",
    "    splittedData = np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "    returnResults= [newArray for newArray in splittedData if len(newArray)>=treshHoldSplit]\n",
    "    return returnResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def consecutive(data, treshHoldSplit,stepsize=1):\n",
    "#     splittedData = np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "#     returnResults = []\n",
    "#     for newArray in splittedData:\n",
    "#         if(len(newArray)!=0):\n",
    "#             if(newArray[0] >= treshHoldSplit):\n",
    "#                 returnResults.append((newArray[0]))\n",
    "#     return returnResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"dataset/extracted/Activity recognition exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(dataDir,dataDirectory):\n",
    "    loadedData = load_file(dataDir+\"/\"+dataDirectory)[1:]\n",
    "    dataInstanceCount = loadedData.shape[0]\n",
    "    returnData = []\n",
    "    for i in range(dataInstanceCount):\n",
    "        returnData.append(np.asarray(loadedData[i][0].split(\",\")))\n",
    "    return returnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviceSamplingRate = [200,200, 200,200,150,150,100,100,100,100,50,50]\n",
    "# deviceWindowFrame = [512,512,512,512,384,384,256,256,256,256,128,128]\n",
    "# downSamplingRate = [4,4,4,4,3,3,2,2,2,2,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadList = ['Phones_accelerometer.csv','Phones_gyroscope.csv','Watch_accelerometer.csv','Watch_gyroscope.csv']\n",
    "# classCounts = ['sit', 'stand', 'walk', 'stairsup', 'stairsdown', 'bike']\n",
    "# classCounts = ['stand','sit', 'walk', 'stairsup', 'stairsdown']\n",
    "classCounts = ['stairsdown','stairsup','bike','sit','stand','walk']\n",
    "\n",
    "deviceCounts = ['nexus4','s3', 's3mini','samsungold']\n",
    "deviceSamplingRate = [200,150,100,50]\n",
    "deviceWindowFrame = [512,384,256,128]\n",
    "downSamplingRate = [4,3,2,1]\n",
    "subDeviceCounts = ['nexus4_1', 'nexus4_2', 'lgwatch_1', 'lgwatch_2', 's3_1', 's3_2', 's3mini_1', 's3mini_2','gear_1', 'gear_2','samsungold_1', 'samsungold_2']\n",
    "userCounts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessedAccData = prepareData(dataDir,\"Phones_accelerometer.csv\")\n",
    "unprocessedGyroData = prepareData(dataDir,\"Phones_gyroscope.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessedAccData = np.asarray(unprocessedAccData)\n",
    "unprocessedGyroData = np.asarray(unprocessedGyroData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allProcessedData = {}\n",
    "allProcessedLabel = {}\n",
    "deviceIndex = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientCount = len(deviceCounts) * len(userCounts)\n",
    "deviceIndexes = {new_list: [] for new_list in range(len(deviceCounts))}\n",
    "clientIndexes = {new_list: [] for new_list in range(len(userCounts))}\n",
    "indexOffset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clientDeviceIndex, deviceName in enumerate(deviceCounts):\n",
    "    print(\"Processsing device \"+str(deviceName))\n",
    "    for clientIDIndex, clientIDName in enumerate(userCounts):\n",
    "        print(\"Processsing device:\"+str(clientDeviceIndex)+\" client \"+str(clientIDIndex))\n",
    "        processedClassData = []\n",
    "        processedClassLabel = []\n",
    "        dataIndex = (unprocessedAccData[:,6] == clientIDName) & (unprocessedAccData[:,7] == deviceName)\n",
    "        userDeviceDataAcc = unprocessedAccData[dataIndex]\n",
    "        if(len(userDeviceDataAcc) == 0):\n",
    "            print(\"No acc data found\")\n",
    "            print(\"Skipping device :\"+str(deviceName) + \" Client: \"+str(clientIDName))\n",
    "            indexOffset += 1\n",
    "            continue\n",
    "        userDeviceDataGyro = unprocessedGyroData[(unprocessedGyroData[:,6] == clientIDName) & (unprocessedGyroData[:,8] == deviceName)]\n",
    "        if(len(userDeviceDataGyro) == 0):\n",
    "            userDeviceDataGyro = unprocessedGyroData[np.where(dataIndex == True)[0]]\n",
    "            \n",
    "        for classIndex, className in enumerate(classCounts):\n",
    "            if(len(userDeviceDataAcc) <= len(userDeviceDataGyro)):\n",
    "                classData = np.where(userDeviceDataAcc[:,9] == className)[0]\n",
    "            else:\n",
    "                classData = np.where(userDeviceDataGyro[:,9] == className)[0]\n",
    "            segmentedClass = consecutive(classData,deviceWindowFrame[int(clientDeviceIndex/2)])\n",
    "            for segmentedClassRange in (segmentedClass):\n",
    "                combinedData = np.dstack((segmentData(userDeviceDataAcc[segmentedClassRange][:,3:6],deviceWindowFrame[clientDeviceIndex],deviceWindowFrame[clientDeviceIndex]/2),segmentData(userDeviceDataGyro[segmentedClassRange][:,3:6],deviceWindowFrame[clientDeviceIndex],deviceWindowFrame[clientDeviceIndex]/2)))\n",
    "                processedClassData.append(combinedData)\n",
    "                processedClassLabel.append(np.full(combinedData.shape[0], classIndex, dtype=int))\n",
    "        deviceCheckIndex = clientDeviceIndex % 2\n",
    "        tempProcessedData = np.vstack((processedClassData))\n",
    "        if(clientDeviceIndex < 5):\n",
    "            tempProcessedData =  downSampleLowPass(np.float32(tempProcessedData),downSamplingRate[clientDeviceIndex])\n",
    "        dataIndex = (len(userCounts) * clientDeviceIndex) + clientIDIndex - indexOffset\n",
    "        print(\"Index is at \"+str(dataIndex))\n",
    "        allProcessedData[dataIndex] = tempProcessedData\n",
    "        allProcessedLabel[dataIndex] = np.hstack((processedClassLabel))\n",
    "        deviceIndex[dataIndex] = np.full(allProcessedLabel[dataIndex].shape[0], clientDeviceIndex)\n",
    "        deviceIndexes[clientDeviceIndex].append(dataIndex)\n",
    "        clientIndexes[clientIDIndex].append(dataIndex)\n",
    "#             print(str(len(allProcessedData)) + \" at \"+ str(clientIDName) + \" and device \" + str(deviceName))\n",
    "#             print(allProcessedLabel[(clientIDIndex * 6) + clientDataIndex].shape)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allProcessedData = np.asarray(list(allProcessedData.items()))[:,1]\n",
    "allProcessedLabel = np.asarray(list(allProcessedLabel.items()))[:,1]\n",
    "deviceIndex =  np.asarray(list(deviceIndex.items()))[:,1]\n",
    "clientIndexes =  np.asarray(list(clientIndexes.items()))[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteIndex = []\n",
    "for index, i in enumerate(allProcessedLabel):\n",
    "    if(len(np.unique(i)) < len(classCounts)):\n",
    "        print(\"Removing client \" + str(index))\n",
    "        print(np.unique(i))\n",
    "        deleteIndex.append(index)\n",
    "        for key, value in dict(deviceIndexes).items():\n",
    "            if(value.count(index)):\n",
    "                value.remove(index)\n",
    "allProcessedLabel = np.delete(allProcessedLabel, deleteIndex)\n",
    "allProcessedData = np.delete(allProcessedData, deleteIndex)\n",
    "deviceIndex = np.delete(deviceIndex, deleteIndex)\n",
    "clientIndexes = np.delete(clientIndexes, deleteIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientRange = [len(arrayLength) for arrayLength in allProcessedLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceSize = []\n",
    "for key, value in dict(deviceIndexes).items():\n",
    "    deviceSize.append(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedData = []\n",
    "endIndex = 0 \n",
    "for i in deviceSize:\n",
    "    startIndex = endIndex\n",
    "    endIndex += i\n",
    "#     print(startIndex)\n",
    "#     print(endIndex)\n",
    "    deviceData = np.vstack(allProcessedData[startIndex:endIndex])\n",
    "    deviceDataAcc = deviceData[:,:,:3].astype(np.float32)\n",
    "    deviceDataGyro = deviceData[:,:,3:].astype(np.float32)\n",
    "    accMean =  np.mean(deviceDataAcc)\n",
    "    accStd =  np.std(deviceDataAcc)\n",
    "    gyroMean =  np.mean(deviceDataGyro)\n",
    "    gyroStd =  np.std(deviceDataGyro)\n",
    "    deviceDataAcc = (deviceDataAcc - accMean)/accStd\n",
    "    deviceDataGyro = (deviceDataGyro - gyroMean)/gyroStd\n",
    "    deviceData = np.dstack((deviceDataAcc,deviceDataGyro))\n",
    "    normalizedData.append(deviceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedData = np.vstack(normalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchSubjectOwner(currentIndex):\n",
    "    for clientID, indexArray in enumerate(clientIndexes):\n",
    "        if(currentIndex in indexArray):\n",
    "            return  clientID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectDataDict = {new_list: [] for new_list in range(len(userCounts))}\n",
    "subjectLabelDict = {new_list: [] for new_list in range(len(userCounts))}\n",
    "\n",
    "startIndex = 0\n",
    "endIndex = 0 \n",
    "for i, dataRange in enumerate(clientRange):\n",
    "    startIndex = endIndex \n",
    "    endIndex = startIndex + dataRange\n",
    "    clientIndex = i%len(userCounts)\n",
    "    subjectDataDict[clientIndex].append(normalizedData[startIndex:endIndex])\n",
    "    subjectLabelDict[clientIndex].append(allProcessedLabel[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(userCounts)):\n",
    "    subjectDataDict[i] = np.vstack((subjectDataDict[i]))\n",
    "    subjectLabelDict[i] = np.hstack((subjectLabelDict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertsDictToArray\n",
    "finalData = np.asarray([np.asarray(subjectDataDict[i]) for i in range(len(userCounts))], dtype=object)\n",
    "finalLabel = np.asarray([np.asarray(subjectLabelDict[i]) for i in range(len(userCounts))], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignedYListClient = []\n",
    "for clientLabel in finalLabel:\n",
    "    alignedClientLabel = np.asarray([7 if labelInstance == 2 else labelInstance for labelInstance in clientLabel])\n",
    "    alignedYListClient.append(alignedClientLabel)\n",
    "alignedYListClient = np.asarray(alignedYListClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLabel = alignedYListClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(label):\n",
    "    onehot_label = tf.one_hot(\n",
    "    label,\n",
    "    10,\n",
    "    on_value=None,\n",
    "    off_value=None,\n",
    "    axis=None,\n",
    "    dtype=None,\n",
    "    name=None\n",
    "    )\n",
    "    return onehot_label\n",
    "\n",
    "finalLabel = np.asarray([oneHot(clientLabel) for clientLabel in finalLabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'HHAR'\n",
    "os.makedirs('datasetClientsUnion/'+dataName, exist_ok=True)\n",
    "hkl.dump(finalData,'datasetClientsUnion/'+dataName+ '/clientsData.hkl' )\n",
    "hkl.dump(finalLabel,'datasetClientsUnion/'+dataName+ '/clientsLabel.hkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data processing finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
