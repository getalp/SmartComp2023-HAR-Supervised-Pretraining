{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl \n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "randomSeed = 0\n",
    "np.random.seed(randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDir = './Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetList = ['HHAR','MobiAct','MotionSense','RealWorld_Waist','UCI','PAMAP'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = 'SSL_PipelineUnion/LODO'\n",
    "os.makedirs(dirName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneDir = 'fineTuneData'\n",
    "testDir = 'testData'\n",
    "valDir = 'valData'\n",
    "datasetDir = 'datasets'\n",
    "os.makedirs(dirName+'/'+datasetDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+fineTuneDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+testDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+valDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datasetIndex,dataSetName in enumerate(datasetList):\n",
    "    datasetLabel = hkl.load(mainDir + 'datasetClientsUnion/'+dataSetName+'/clientsLabel.hkl')\n",
    "    datasetTrain = hkl.load(mainDir + 'datasetClientsUnion/'+dataSetName+'/clientsData.hkl')\n",
    "    print(\"Dataset: \"+str(dataSetName) +\" Shape: \" + str(np.unique(np.argmax(np.vstack((datasetLabel)),axis = -1 ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneData = []\n",
    "fineTuneLabel = []\n",
    "\n",
    "for datasetIndex,dataSetName in enumerate(datasetList):\n",
    "    datasetLabel = hkl.load(mainDir + 'datasetClientsUnion/'+dataSetName+'/clientsLabel.hkl')\n",
    "    datasetTrain = hkl.load(mainDir + 'datasetClientsUnion/'+dataSetName+'/clientsData.hkl')\n",
    "    hkl.dump(datasetTrain,dirName+'/'+datasetDir+ '/'+dataSetName+'_data.hkl')\n",
    "    hkl.dump(datasetLabel,dirName+'/'+datasetDir+ '/'+dataSetName+'_label.hkl')\n",
    "    trainingData = []\n",
    "    testingData = []\n",
    "    validatingData = []\n",
    "    \n",
    "    trainingLabel = []\n",
    "    testingLabel = []\n",
    "    validatingLabel = []\n",
    "    \n",
    "    for datasetData, datasetLabels in zip(datasetTrain,datasetLabel):\n",
    "        nonSoftMaxedLabels = np.argmax(datasetLabels,axis = -1)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=10,shuffle = False)\n",
    "        skf.get_n_splits(datasetData, nonSoftMaxedLabels)\n",
    "        partitionedData = list()\n",
    "        partitionedLabel = list()\n",
    "        testIndex = []\n",
    "        \n",
    "        for train_index, test_index in skf.split(datasetData, nonSoftMaxedLabels):\n",
    "            testIndex.append(test_index)\n",
    "\n",
    "        trainIndex = np.hstack((testIndex[:7]))\n",
    "        devIndex = testIndex[8]\n",
    "        testIndex = np.hstack((testIndex[8:]))\n",
    "\n",
    "        X_train = tf.gather(datasetData,trainIndex).numpy()\n",
    "        X_val = tf.gather(datasetData,devIndex).numpy()\n",
    "        X_test = tf.gather(datasetData,testIndex).numpy()\n",
    "\n",
    "        y_train = tf.gather(nonSoftMaxedLabels,trainIndex).numpy()\n",
    "        y_val = tf.gather(nonSoftMaxedLabels,devIndex).numpy()\n",
    "        y_test = tf.gather(nonSoftMaxedLabels,testIndex).numpy()\n",
    "        \n",
    "        y_train = tf.one_hot(y_train,10)\n",
    "        y_val = tf.one_hot(y_val,10)\n",
    "        y_test = tf.one_hot(y_test,10)\n",
    "\n",
    "        trainingData.append(X_train)\n",
    "        validatingData.append(X_val)\n",
    "        testingData.append(X_test)\n",
    "        \n",
    "        trainingLabel.append(y_train)\n",
    "        validatingLabel.append(y_val)\n",
    "        testingLabel.append(y_test)\n",
    "        \n",
    "        \n",
    "    testingLabel = np.asarray(testingLabel)\n",
    "    testingData = np.asarray(testingData)\n",
    "    \n",
    "    validatingData = np.asarray(validatingData)\n",
    "    validatingLabel = np.asarray(validatingLabel)\n",
    "\n",
    "    trainingLabel = np.asarray(trainingLabel)\n",
    "    trainingData = np.asarray(trainingData)\n",
    "    \n",
    "    fineTuneData.append(trainingData)\n",
    "    fineTuneLabel.append(trainingLabel)\n",
    "\n",
    "    hkl.dump(trainingData,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_70_data.hkl')\n",
    "    hkl.dump(trainingLabel,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_70_label.hkl')\n",
    "    hkl.dump(testingData,dirName+'/'+testDir+ '/'+dataSetName+'_data.hkl' )\n",
    "    hkl.dump(testingLabel,dirName+'/'+testDir+ '/'+dataSetName+'_label.hkl' )\n",
    "    hkl.dump(validatingData,dirName+'/'+valDir+ '/'+dataSetName+'_data.hkl' )\n",
    "    hkl.dump(validatingLabel,dirName+'/'+valDir+ '/'+dataSetName+'_label.hkl' )\n",
    "fineTuneData = np.asarray(fineTuneData)\n",
    "fineTuneLabel = np.asarray(fineTuneLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneRatio = [1.0,5.0,10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneData = np.asarray(fineTuneData)\n",
    "fineTuneLabel = np.asarray(fineTuneLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSamplesUserDataset = []\n",
    "for ratio in fineTuneRatio:\n",
    "    datasetIndex = 0\n",
    "    for trainingDataSubject, traningLabelSubject in zip(fineTuneData,fineTuneLabel):\n",
    "        trainingDataSave = []\n",
    "        trainingLabelSave = []\n",
    "        sampleCount = []\n",
    "        leaveOutRatio = (70.0 - ratio)/70.0\n",
    "        print(\"Processing \"+str(datasetList[datasetIndex]) + \" with ratio: \"+str(ratio))\n",
    "        for subjectData, subjectLabel in zip(trainingDataSubject,traningLabelSubject):\n",
    "            softMaxedLabels = np.argmax(subjectLabel,axis = -1)        \n",
    "            if(((1-leaveOutRatio) * len(softMaxedLabels)) < 10):\n",
    "                print(\"1% ratio unable to get 1 sample of each activity in \"+str(datasetList[datasetIndex]) +\" dataset\")\n",
    "                classIndex = np.unique(softMaxedLabels,return_index = True)[1]\n",
    "                y_train = tf.one_hot(tf.gather(softMaxedLabels,classIndex).numpy(),10)\n",
    "                trainingDataSave.append(tf.gather(subjectData,classIndex).numpy())\n",
    "                trainingLabelSave.append(y_train)    \n",
    "                sampleCount.append(trainingLabelSave[-1].shape[0])\n",
    "            else:\n",
    "                smallClass = np.where(np.unique(softMaxedLabels,return_counts=True)[1] < 10 )\n",
    "                print(smallClass)\n",
    "                if(len(smallClass) > 0):\n",
    "                    for classToRemove in smallClass:\n",
    "                        print(\"To remove index due to too few classes\")\n",
    "                        indicesRemove = np.where(softMaxedLabels == classToRemove)[0]\n",
    "                        print(indicesRemove)\n",
    "                        softMaxedLabels = np.delete(softMaxedLabels, indicesRemove,axis = 0)\n",
    "                        subjectData = np.delete(subjectData, indicesRemove,axis = 0)\n",
    "                X_train, X_val_test, y_train, y_val_test = train_test_split(subjectData, softMaxedLabels,\n",
    "                                                            stratify=softMaxedLabels, \n",
    "                                                            random_state = randomSeed,\n",
    "                                                            test_size=leaveOutRatio)\n",
    "                y_train = tf.one_hot(y_train,10)\n",
    "                trainingDataSave.append(X_train)\n",
    "                trainingLabelSave.append(y_train)    \n",
    "                sampleCount.append(trainingLabelSave[-1].shape[0])\n",
    "\n",
    "        trainingLabelSave = np.asarray(trainingLabelSave)\n",
    "        trainingDataSave = np.asarray(trainingDataSave)\n",
    "        \n",
    "        print(\"Dataset : \"+str(datasetList[datasetIndex]))\n",
    "        print(np.unique(np.argmax(np.vstack((trainingLabelSave)),-1), return_counts = True))\n",
    "        \n",
    "        meanSampleCount = int(np.mean(sampleCount))\n",
    "        print(\"Mean samples per dataset is \"+str(meanSampleCount))\n",
    "        meanSamplesUserDataset.append(meanSampleCount)\n",
    "        hkl.dump(trainingDataSave,dirName+'/'+fineTuneDir+ '/'+datasetList[datasetIndex]+'_'+str(int(ratio))+'_data.hkl')\n",
    "        hkl.dump(trainingLabelSave,dirName+'/'+fineTuneDir+ '/'+datasetList[datasetIndex]+'_'+str(int(ratio))+'_label.hkl')\n",
    "        datasetIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
